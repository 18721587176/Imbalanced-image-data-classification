{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,optimizers,losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os, glob\n",
    "import random, csv\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn import model_selection,svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score,\\\n",
    "                precision_recall_curve,roc_curve,roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "path = \"/content/drive/My Drive\"\n",
    "os.chdir(path)\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mean = tf.constant([0.485, 0.456, 0.406])\n",
    "img_std = tf.constant([0.229, 0.224, 0.225])\n",
    "def normalize(x, mean=img_mean, std=img_std):\n",
    "    # x: [224, 224, 3]\n",
    "    # mean: [224, 224, 3], std: [3]\n",
    "    x = (x - mean)/std\n",
    "    return x\n",
    "\n",
    "def denormalize(x, mean=img_mean, std=img_std):\n",
    "    x = x * std + mean\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(root, filename, name2label):\n",
    "\n",
    "    if not os.path.exists(os.path.join(root, filename)):\n",
    "        images = []\n",
    "        for name in name2label.keys():\n",
    "       \n",
    "            images += glob.glob(os.path.join(root, name, '*.png'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpg'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpeg'))\n",
    "\n",
    "        print(len(images), images)\n",
    "\n",
    "        random.shuffle(images)\n",
    "        with open(os.path.join(root, filename), mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for img in images:  \n",
    "                name = img.split(os.sep)[-2]\n",
    "                label = name2label[name]\n",
    "              \n",
    "                writer.writerow([img, label])\n",
    "            print('written into csv file:', filename)\n",
    "            \n",
    "                # read from csv file\n",
    "    images, labels = [], []\n",
    "    with open(os.path.join(root, filename)) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            \n",
    "            img, label = row\n",
    "            label = int(label)\n",
    "\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "    assert len(images) == len(labels)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(x,y):\n",
    "   \n",
    "    x = tf.io.read_file(x)\n",
    "    x = tf.image.decode_jpeg(x, channels=3) \n",
    "    x = tf.image.resize(x, [244, 244])\n",
    "\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "    x = tf.image.random_crop(x, [224,224,3])\n",
    "\n",
    "    # x: [0,255]=> -1~1\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    x = normalize(x)\n",
    "    y = tf.convert_to_tensor(y)\n",
    "    y = tf.one_hot(y, depth=2)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root, mode='train'):\n",
    " \n",
    "    name2label = {}  \n",
    "    for name in sorted(os.listdir(os.path.join(root))):\n",
    "        if not os.path.isdir(os.path.join(root, name)):\n",
    "            continue\n",
    "     \n",
    "        name2label[name] = len(name2label.keys())\n",
    "\n",
    "    images, labels = load_csv(root, 'binary0.2_images.csv', name2label)\n",
    "\n",
    "    if mode == 'train':  # 60%\n",
    "        images = images[:int(0.6 * len(images))]\n",
    "        labels = labels[:int(0.6 * len(labels))]\n",
    "    elif mode == 'val':  # 20% = 60%->80%\n",
    "        images = images[int(0.6 * len(images)):int(0.8 * len(images))]\n",
    "        labels = labels[int(0.6 * len(labels)):int(0.8 * len(labels))]\n",
    "    else:  # 20% = 80%->100%\n",
    "        images = images[int(0.8 * len(images)):]\n",
    "        labels = labels[int(0.8 * len(labels)):]\n",
    "\n",
    "    return images, labels, name2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsz = 128\n",
    "# 创建训练集Datset对象\n",
    "images, labels, table = load_data('数据集ratio=0.025',mode='train')\n",
    "db_train = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "db_train = db_train.shuffle(1000).map(preprocess).batch(batchsz)\n",
    "# 创建验证集Datset对象\n",
    "images2, labels2, table = load_data('数据集ratio=0.025',mode='val')\n",
    "db_val = tf.data.Dataset.from_tensor_slices((images2, labels2))\n",
    "db_val = db_val.map(preprocess).batch(batchsz)\n",
    "# 创建测试集Datset对象\n",
    "images3, labels3, table = load_data('数据集ratio=0.025',mode='test')\n",
    "db_test = tf.data.Dataset.from_tensor_slices((images3, labels3))\n",
    "db_test = db_test.map(preprocess).batch(batchsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net10 = keras.applications.VGG19(weights='imagenet', include_top=False,\n",
    "                               pooling='max')\n",
    "net10.trainable = False\n",
    "newnet = keras.Sequential([\n",
    "    net10,\n",
    "    layers.Dense(2) # 输出层单元个数\n",
    "])\n",
    "newnet.build(input_shape=(4,224,224,3))\n",
    "newnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newnet.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
    "               loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy'])\n",
    "newnet.fit(db_train, validation_data=db_val, validation_freq=1, epochs=100\n",
    "           )\n",
    "newnet.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= newnet.predict_classes(db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_all(x_test, y_test, y_pred):\n",
    "    # y_pred= model.predict_classes(x_test)\n",
    "    #  auc 面积计算\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    print('auc面积 = {0}\\n'.format(auc))\n",
    "    # F1-score 计算\n",
    "    f1_micro = f1_score(y_test,y_pred,average='micro')\n",
    "    f1_macro = f1_score(y_test,y_pred,average='macro') \n",
    "    print('f1_score_minority = {0}\\n'.format(f1_micro))\n",
    "    print('f1_score_majority = {0}\\n'.format(f1_micro))\n",
    "    # precision, recall 计算\n",
    "    con_matrix=confusion_matrix(y_test,y_pred)\n",
    "    P=precision_score(y_test,y_pred,average='binary')\n",
    "    R=recall_score(y_test,y_pred,average='binary')\n",
    "    F1=f1_score(y_test,y_pred,average='binary')\n",
    "    precision,recall,_=precision_recall_curve(y_test,y_pred)\n",
    "    fpr,tpr,_=roc_curve(y_test,y_pred)\n",
    "    print('precison = {}\\n'.format(P))\n",
    "    print('recall_score = {}\\n'.format(R))\n",
    "    # G-mean 计算\n",
    "    G_mean=geometric_mean_score(y_test, y_pred)\n",
    "    print('G-mean = {}\\n'.format(G_mean))\n",
    "    # imbalance report       \n",
    "    target_names = ['class 0', 'class 1'] # doctest : +NORMALIZE_WHITESPACE\n",
    "    print(classification_report_imbalanced(y_test, y_pred,     target_names=target_names))\n",
    "    # ROC 曲线绘制\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % auc)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all(images3, labels3, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
